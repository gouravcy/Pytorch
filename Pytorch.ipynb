{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([2.5, 0.1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7445, 0.5377],\n",
      "        [0.6258, 0.8636]])\n",
      "tensor([[0.8489, 0.0917],\n",
      "        [0.1729, 0.9670]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(2,2)\n",
    "b=torch.rand(2,2)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5934, 0.6295],\n",
       "        [0.7988, 1.8306]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9067, 0.5982, 0.5900, 0.7588],\n",
      "        [0.1389, 0.2979, 0.7359, 0.6581],\n",
      "        [0.1456, 0.1585, 0.0523, 0.5224],\n",
      "        [0.6109, 0.1047, 0.0832, 0.4587]])\n"
     ]
    }
   ],
   "source": [
    "c=torch.rand(4,4)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9067, 0.5982],\n",
      "        [0.5900, 0.7588],\n",
      "        [0.1389, 0.2979],\n",
      "        [0.7359, 0.6581],\n",
      "        [0.1456, 0.1585],\n",
      "        [0.0523, 0.5224],\n",
      "        [0.6109, 0.1047],\n",
      "        [0.0832, 0.4587]])\n"
     ]
    }
   ],
   "source": [
    "d=c.view(-1,2)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(6)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "b=torch.from_numpy(a)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0101, 1.3532, 0.6393], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0101, 3.3532, 2.6393], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y=x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3333, 0.3333, 0.3333])\n"
     ]
    }
   ],
   "source": [
    "y=y.mean()\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5354, 3.0396, 0.3346])\n"
     ]
    }
   ],
   "source": [
    "v=torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "z.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ways to instruct tensor not to learn from the gradient history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.requires_grad_(False)\n",
    "#x.detach()\n",
    "#with torch.nograd():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way to reset grad to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "for epoch in range(3):\n",
    "    model_op=(weights*3).sum()\n",
    "    print(model_op)\n",
    "    model_op.backward()\n",
    "    print(weights.grad)\n",
    "    \n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    " import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(1.0)\n",
    "y=torch.tensor(2.0)\n",
    "\n",
    "w=torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#forward pass\n",
    "y_hat= w*x\n",
    "loss=(y_hat-y)**2\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "#backward pass\n",
    "loss.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradientdescent conventional method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([1,2,3,4])\n",
    "Y=np.array([2,4,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output\n",
    "def forward(x):\n",
    "    return w*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss=Mean squared Error\n",
    "def loss(y, y_pred):\n",
    "    return((y_pred-y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x,y,y_pred):\n",
    "    return np.dot(2*x, y_pred-y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prection of model before training: Forward(5) = 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prection of model before training: Forward(5) = {forward(5):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "lr=0.01\n",
    "iteration=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 1.200, loss = 30.00000000\n",
      "epoch 2: w = 1.680, loss = 4.80000000\n",
      "epoch 3: w = 1.872, loss = 0.76800000\n",
      "epoch 4: w = 1.949, loss = 0.12288000\n",
      "epoch 5: w = 1.980, loss = 0.01966080\n",
      "epoch 6: w = 1.992, loss = 0.00314573\n",
      "epoch 7: w = 1.997, loss = 0.00050332\n",
      "epoch 8: w = 1.999, loss = 0.00008053\n",
      "epoch 9: w = 1.999, loss = 0.00001288\n",
      "epoch 10: w = 2.000, loss = 0.00000206\n",
      "epoch 11: w = 2.000, loss = 0.00000033\n",
      "epoch 12: w = 2.000, loss = 0.00000005\n",
      "epoch 13: w = 2.000, loss = 0.00000001\n",
      "epoch 14: w = 2.000, loss = 0.00000000\n",
      "epoch 15: w = 2.000, loss = 0.00000000\n",
      "epoch 16: w = 2.000, loss = 0.00000000\n",
      "epoch 17: w = 2.000, loss = 0.00000000\n",
      "epoch 18: w = 2.000, loss = 0.00000000\n",
      "epoch 19: w = 2.000, loss = 0.00000000\n",
      "epoch 20: w = 2.000, loss = 0.00000000\n",
      "Prection of model after training: Forward(5) = 10.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(iteration):\n",
    "    y_prediction=forward(X)\n",
    "    l=loss(Y,y_prediction)\n",
    "    dw=gradient(X,Y, y_prediction)\n",
    "    w-= lr*dw\n",
    "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "print(f\"Prection of model after training: Forward(5) = {forward(5):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "Y=torch.tensor([2,4,6,8], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=torch.tensor(0.0, dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output\n",
    "def forward(x):\n",
    "    return w*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss=Mean squared Error\n",
    "def loss(y, y_pred):\n",
    "    return((y_pred-y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prection of model before training: Forward(5) = 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prection of model before training: Forward(5) = {forward(5):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "lr=0.01\n",
    "iteration=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 1.946, loss = 0.04506890\n",
      "epoch 2: w = 1.954, loss = 0.02208375\n",
      "epoch 3: w = 1.961, loss = 0.01595551\n",
      "epoch 4: w = 1.967, loss = 0.01152786\n",
      "epoch 5: w = 1.972, loss = 0.00832885\n",
      "epoch 6: w = 1.976, loss = 0.00601758\n",
      "epoch 7: w = 1.980, loss = 0.00434770\n",
      "epoch 8: w = 1.983, loss = 0.00314120\n",
      "epoch 9: w = 1.985, loss = 0.00226952\n",
      "epoch 10: w = 1.987, loss = 0.00163972\n",
      "epoch 11: w = 1.989, loss = 0.00118470\n",
      "epoch 12: w = 1.991, loss = 0.00085596\n",
      "epoch 13: w = 1.992, loss = 0.00061843\n",
      "epoch 14: w = 1.993, loss = 0.00044682\n",
      "epoch 15: w = 1.994, loss = 0.00032283\n",
      "epoch 16: w = 1.995, loss = 0.00023325\n",
      "epoch 17: w = 1.996, loss = 0.00016852\n",
      "epoch 18: w = 1.997, loss = 0.00012175\n",
      "epoch 19: w = 1.997, loss = 0.00008797\n",
      "epoch 20: w = 1.998, loss = 0.00006356\n",
      "Prection of model after training: Forward(5) = 9.9876\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(iteration):\n",
    "    y_prediction=forward(X)\n",
    "    l=loss(Y,y_prediction)\n",
    "    l.backward()\n",
    "    with torch.no_grad():\n",
    "        w-= lr*w.grad\n",
    "    w.grad.zero_()\n",
    "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "print(f\"Prection of model after training: Forward(5) = {forward(5):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
    "Y=torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 4, #features: 1\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_features = X.shape\n",
    "print(f'#samples: {n_samples}, #features: {n_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=torch.tensor([5], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=n_features\n",
    "output_size=n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin=nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LinearRegression(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = -0.731\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "n_iters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 : w =  -0.012923809699714184  loss =  tensor(31.0836, grad_fn=<MseLossBackward>)\n",
      "epoch  11 : w =  1.271174430847168  loss =  tensor(1.1372, grad_fn=<MseLossBackward>)\n",
      "epoch  21 : w =  1.48968505859375  loss =  tensor(0.3430, grad_fn=<MseLossBackward>)\n",
      "epoch  31 : w =  1.5364434719085693  loss =  tensor(0.3042, grad_fn=<MseLossBackward>)\n",
      "epoch  41 : w =  1.5552328824996948  loss =  tensor(0.2860, grad_fn=<MseLossBackward>)\n",
      "epoch  51 : w =  1.569190502166748  loss =  tensor(0.2694, grad_fn=<MseLossBackward>)\n",
      "epoch  61 : w =  1.582047939300537  loss =  tensor(0.2537, grad_fn=<MseLossBackward>)\n",
      "epoch  71 : w =  1.5944150686264038  loss =  tensor(0.2389, grad_fn=<MseLossBackward>)\n",
      "epoch  81 : w =  1.6063989400863647  loss =  tensor(0.2250, grad_fn=<MseLossBackward>)\n",
      "epoch  91 : w =  1.6180258989334106  loss =  tensor(0.2119, grad_fn=<MseLossBackward>)\n",
      "Prediction after training: f(5) = 9.234\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_iters):\n",
    "    \n",
    "    y_predicted = model(X)\n",
    "\n",
    "    \n",
    "    l = loss(Y, y_predicted)\n",
    "\n",
    "    \n",
    "    l.backward()\n",
    "\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        [w, b] = model.parameters() # unpack parameters\n",
    "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
    "\n",
    "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.55385928e+01 -1.06619847e+01  2.27574081e+01  1.01096129e+02\n",
      "  1.44337558e+02  3.32888330e+01  3.30152710e+01 -2.58869694e+01\n",
      " -9.96391397e+01  2.38030714e+01 -4.55886864e+01 -8.33875709e+00\n",
      " -9.53154191e+01  3.64072963e+01 -8.72926036e+01  6.76693724e+01\n",
      " -1.36866100e+01 -5.54414224e+01 -6.53402399e+01 -5.44497141e+01\n",
      " -2.88351332e+01  1.78835048e+02  6.50839520e+01  2.66683131e+01\n",
      " -1.85459706e+01 -4.14990408e+01  8.55827764e-01  4.45616521e+01\n",
      "  1.15984811e+02 -6.46197993e+01 -2.59312718e+01 -6.08820426e+01\n",
      "  1.87195482e+01  7.50696998e+01  1.17203175e+02 -2.26982690e+01\n",
      " -5.63625811e+01  1.80837188e+02 -1.92574950e+02  6.85032358e+01\n",
      "  1.65522025e+02  1.05000391e+02 -7.04338757e+01 -5.87693362e+01\n",
      " -4.15757142e+01  7.32472269e+01  4.09664082e+01  8.04619460e+01\n",
      " -2.87939943e+01  3.42341054e+01 -4.17148764e+01  1.43547375e+01\n",
      "  7.93363240e+01  2.71292073e+01 -3.94873551e+01  6.68052070e+01\n",
      "  9.55308437e+01  3.56104075e+00  1.08568943e-01  5.64952893e+01\n",
      "  5.15753413e+01 -2.09741113e+00 -2.66559439e+01  3.97419819e+01\n",
      "  3.61014055e+01 -7.56019440e+01  1.97126065e+01 -7.16010331e+01\n",
      " -1.99035774e+01 -7.67084296e+01 -1.18338274e+02 -2.98246083e+01\n",
      "  1.51082783e+02  5.29226489e+01 -5.95516769e+01  3.07214747e+01\n",
      " -2.93550664e+01 -4.47861678e+01  1.00058362e+02  1.50576548e+02\n",
      "  1.22000422e+02 -1.81857166e+02  3.47392430e+00 -2.29801423e+01\n",
      "  4.51842772e+01  9.86063300e+01 -9.27788339e+00 -5.24778810e+01\n",
      "  3.85928318e+01 -1.99972423e+02 -9.52014653e+00 -3.47236288e+00\n",
      " -3.53122497e+01  7.54057582e+01  1.75701411e+01 -2.39600185e+01\n",
      "  1.32085955e+02  2.06075830e+01  5.11112097e+01 -2.63060397e+01]\n"
     ]
    }
   ],
   "source": [
    "print(y_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.61175641]\n",
      " [-0.24937038]\n",
      " [ 0.48851815]\n",
      " [ 0.76201118]\n",
      " [ 1.51981682]\n",
      " [ 0.37756379]\n",
      " [ 0.51292982]\n",
      " [-0.67124613]\n",
      " [-1.39649634]\n",
      " [ 0.31563495]\n",
      " [-0.63699565]\n",
      " [-0.39675353]\n",
      " [-1.10061918]\n",
      " [ 0.90085595]\n",
      " [-1.09989127]\n",
      " [ 0.82797464]\n",
      " [-0.07557171]\n",
      " [-0.35224985]\n",
      " [-0.67066229]\n",
      " [-1.07296862]\n",
      " [-0.30620401]\n",
      " [ 2.18557541]\n",
      " [ 0.86540763]\n",
      " [ 0.19829972]\n",
      " [-0.38405435]\n",
      " [-0.68372786]\n",
      " [ 0.05080775]\n",
      " [ 0.58281521]\n",
      " [ 1.25286816]\n",
      " [-0.75439794]\n",
      " [-0.34934272]\n",
      " [-0.88762896]\n",
      " [ 0.18656139]\n",
      " [ 0.87616892]\n",
      " [ 0.83898341]\n",
      " [-0.50446586]\n",
      " [-0.34385368]\n",
      " [ 1.6924546 ]\n",
      " [-2.3015387 ]\n",
      " [ 0.93110208]\n",
      " [ 2.10025514]\n",
      " [ 1.46210794]\n",
      " [-0.84520564]\n",
      " [-0.87785842]\n",
      " [-0.3224172 ]\n",
      " [ 0.88514116]\n",
      " [ 0.16003707]\n",
      " [ 1.13162939]\n",
      " [-0.37528495]\n",
      " [ 0.50249434]\n",
      " [-0.20889423]\n",
      " [ 0.12015895]\n",
      " [ 0.58662319]\n",
      " [ 0.3190391 ]\n",
      " [-0.69166075]\n",
      " [ 0.69803203]\n",
      " [ 1.19891788]\n",
      " [-0.20075807]\n",
      " [ 0.53035547]\n",
      " [ 0.74204416]\n",
      " [ 0.41005165]\n",
      " [ 0.11900865]\n",
      " [-0.7612069 ]\n",
      " [ 0.42349435]\n",
      " [ 0.30017032]\n",
      " [-1.1425182 ]\n",
      " [ 0.18515642]\n",
      " [-0.93576943]\n",
      " [-0.62000084]\n",
      " [-1.11731035]\n",
      " [-1.44411381]\n",
      " [-0.22232814]\n",
      " [ 1.62434536]\n",
      " [ 0.61720311]\n",
      " [-0.6871727 ]\n",
      " [ 0.07734007]\n",
      " [-0.0126646 ]\n",
      " [-0.63873041]\n",
      " [ 1.13376944]\n",
      " [ 1.74481176]\n",
      " [ 0.90159072]\n",
      " [-2.06014071]\n",
      " [ 0.2344157 ]\n",
      " [-0.17242821]\n",
      " [ 0.12182127]\n",
      " [ 1.14472371]\n",
      " [-0.12289023]\n",
      " [-0.74715829]\n",
      " [ 0.28558733]\n",
      " [-2.02220122]\n",
      " [ 0.23009474]\n",
      " [-0.26788808]\n",
      " [-0.52817175]\n",
      " [ 1.12948391]\n",
      " [ 0.19091548]\n",
      " [-0.29809284]\n",
      " [ 1.65980218]\n",
      " [ 0.04359686]\n",
      " [ 0.04221375]\n",
      " [-0.19183555]]\n"
     ]
    }
   ],
   "source": [
    "print(X_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer=datasets.load_breast_cancer()\n",
    "X,y = breast_cancer.data, breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features=X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(n_samples)\n",
    "print(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model,self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred=torch.sigmoid(self.linear(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 0.2272\n",
      "epoch: 20, loss = 0.2272\n",
      "epoch: 30, loss = 0.2272\n",
      "epoch: 40, loss = 0.2272\n",
      "epoch: 50, loss = 0.2272\n",
      "epoch: 60, loss = 0.2272\n",
      "epoch: 70, loss = 0.2272\n",
      "epoch: 80, loss = 0.2272\n",
      "epoch: 90, loss = 0.2272\n",
      "epoch: 100, loss = 0.2272\n",
      "accuracy: 0.9123\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    y_pred=model(X_train)\n",
    "    loss=criterion(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.zero_grad()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy: {acc.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transformer and Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        dataset_loading=np.loadtxt('/home/gourav/Downloads/9408623-b237fa5848349a14a14e5d4107dc7897c21951f5/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.n_samples=dataset_loading.shape[0]\n",
    "        \n",
    "        self.x_data=dataset_loading[:,1:]\n",
    "        self.y_data=dataset_loading[:,[0]]\n",
    "        \n",
    "        self.transform=transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sample= self.x_data[index], self.y_data[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, results = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With Tensor Transform\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "print('\\nWith Tensor Transform')\n",
    "dataset = WineDataset(transform=ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(dataset=dataset,\n",
    "                       batch_size=4,\n",
    "                       shuffle=True,\n",
    "                       num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3170e+01, 2.5900e+00, 2.3700e+00, 2.0000e+01, 1.2000e+02, 1.6500e+00,\n",
      "         6.8000e-01, 5.3000e-01, 1.4600e+00, 9.3000e+00, 6.0000e-01, 1.6200e+00,\n",
      "         8.4000e+02],\n",
      "        [1.2850e+01, 1.6000e+00, 2.5200e+00, 1.7800e+01, 9.5000e+01, 2.4800e+00,\n",
      "         2.3700e+00, 2.6000e-01, 1.4600e+00, 3.9300e+00, 1.0900e+00, 3.6300e+00,\n",
      "         1.0150e+03],\n",
      "        [1.2040e+01, 4.3000e+00, 2.3800e+00, 2.2000e+01, 8.0000e+01, 2.1000e+00,\n",
      "         1.7500e+00, 4.2000e-01, 1.3500e+00, 2.6000e+00, 7.9000e-01, 2.5700e+00,\n",
      "         5.8000e+02],\n",
      "        [1.4060e+01, 2.1500e+00, 2.6100e+00, 1.7600e+01, 1.2100e+02, 2.6000e+00,\n",
      "         2.5100e+00, 3.1000e-01, 1.2500e+00, 5.0500e+00, 1.0600e+00, 3.5800e+00,\n",
      "         1.2950e+03]]) tensor([[3.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "dataiterator=iter(train_loader)\n",
    "data=dataiterator.next()\n",
    "features, labels=data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n"
     ]
    }
   ],
   "source": [
    "num_epochs=2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_enviroment",
   "language": "python",
   "name": "pytorch_enviroment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
